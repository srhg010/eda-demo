#+title: EDA Demo

* TODO El de la calibración de los medidores de la calidad del aire.

** TODO Gráficas [0/1]

*** TODO


* El de la predicción del peso de los burritos con sólo saber la altura.
** DONE Gráficas [100%]
*** DONE Creación [11/11]
- [X] figure_01
- [X] figure_02
- [X] figure_03
- [X] figure_04
- [X] figure_05
- [X] figure_06
- [X] figure_07
- [X] figure_08
- [X] figure_09
- [X] figure_10
- [X] figure_11
*** DONE Guardarlas [11/11]
- [X] figure_01
- [X] figure_02
- [X] figure_03
- [X] figure_04
- [X] figure_05
- [X] figure_06
- [X] figure_07
- [X] figure_08
- [X] figure_09
- [X] figure_10
- [X] figure_11
* TODO El análisis de los discursos de los presidentes.
** HOLD Explicación (Claude)
I'd be happy to help you understand the PCA results in this text analysis script. Let's break down what's happening in the code and how to interpret the results.

*** What this PCA Analysis Is Doing

This script is performing Principal Component Analysis on a corpus of US State of the Union speeches from 1790 to 2022. Here's the process:

1. **Text Preprocessing**:
   - The text is cleaned by removing bracketed content, converting to lowercase, and removing non-alphabetic characters
   - Stop words are removed (common words like "the", "and", etc.)
   - Words are stemmed using Porter Stemmer (reducing words to their root form)

2. **Vectorization**:
   - The TF-IDF (Term Frequency-Inverse Document Frequency) vectorizer converts each speech into a numerical vector
   - Each speech becomes a vector in a 13,211-dimensional space (one dimension per unique word stem)
   - The message indicates "232 speeches transformed into vectors of 13,211 words"

3. **Dimensionality Reduction with PCA**:
   - The script uses Singular Value Decomposition (SVD) to compute the principal components
   - It extracts the first 2 principal components (k=2)

4. **Visualization**:
   - The speeches are plotted in a 2D space defined by the first two principal components
   - Points are colored by year (from oldest to newest) using the "nipy_spectral" colormap
   - The 5 most recent speeches are annotated with the president's name

*** Interpreting the Results

In this PCA plot:

1. *Each Point*: Represents one State of the Union speech

2. *PC1 and PC2 (The Axes)*:
   - These are the first two principal components - directions in the 13,211-dimensional word space that capture the most variance
   - PC1 captures the most variance, PC2 captures the second most

3. *Color Gradient*:
   - The colors represent years, allowing you to see temporal trends in language

4. *Position of Points*:
   - Points that are close together in this 2D space have similar language patterns
   - Points that are far apart have very different language

5. *What to Look For*:
   - **Clusters**: Groups of speeches that use similar language
   - *Temporal Trends*: Does language evolve gradually over time (smooth color transition) or are there abrupt changes?
   - *Outliers*: Speeches that stand out from others of their era

6. *The PC Adjustment*:
   #+begin_src python
   if pcs[0, 0] < 0:
       pcs[:,] *= -1
   if pcs[0, 1] < 0:
       pcs[:, 1] *= -1
   #+end_src
   This is just flipping the directions to maintain a consistent orientation (the signs of eigenvectors are arbitrary).

*** To Better Understand the Components

The script doesn't explicitly show what each principal component represents in terms of words. To understand what PC1 and PC2 actually mean in terms of language features, you would want to examine the loadings (weights) of different words on these components.

You could add code like this to see which words are most strongly associated with each component:

#+begin_src python
# Get feature names (words)
feature_names = tfidf.get_feature_names_out()

# Get the components (loadings)
components = svds(speech_vectors - speech_vectors.mean(axis=0), k=2)[2]

# For each component, print the top words
for i, component in enumerate(components):
    # Get indices of top weighted words
    sorted_indices = np.argsort(np.abs(component))[::-1][:10]
    top_words = [(feature_names[idx], component[idx]) for idx in sorted_indices]
    print(f"PC{i+1} top words:")
    for word, weight in top_words:
        print(f"  {word}: {weight:.4f}")
#+end_src

This would help you interpret what linguistic features each principal component represents, allowing you to say something more meaningful than just "this is PC1" - instead, you could say "PC1 appears to represent the shift from formal/constitutional language to more modern policy-focused language" (or whatever the components actually capture).
** DONE Gráfica
*** DONE Guardarla
** IDEA Concomitar un UMAP al PCA
* San Francisco Housing
** Prolegomena
- Los datos fueron recopilados (/scraped/) del San Francisco Chronicle [[https://www.sfchronicle.com/realestate/][Complete real estate coverage of the SF Bay Area]]
- Los datos son una lista de casas vendidas en el área de abril de 2003 a diciembre de 2008.
- Es una exploración sin interés en generalizar, entonces la población, la muestra y el marco de acceso[fn:1] son el mismo.
- La granularidad[fn:2] de los datos está al nivel de una venta.
-
** Understanding Price
- Son dos *gráficas*
    #+name: figura 1
  - histograma =under_4m=
    #+name: figura 2
  - histograma =under_4m log=
** What Next?
- El mercado de bienes raíces estaba creciendo rápidamente en esta época.
- Colapsó en el 2008.
- Elijamos una opción:
  a. Analizar el comportamiento de los precios a lo largo del tiempo.
  b. Fijar un año y explorar la relación del precio con las otras variables.
- Elijamos la opción =b.= y fijemos el año a 2004.
- Después concentremos el análisis para las casas de menos de $4M y menores a 12,000 ft^{2}.
  - Se hace un subconjunto de los datos con las columnas que cumplen estas dos características.
- Veamos si existen otras variables que puedan ser importantes en nuestro análisis en relación al precio.
** Examining Other Features
- Muy probablemente:
  1. tamaño de la casa
  2. tamaño del terreno
  3. número de cuartos
- Exploremos la distribución de estas características y sus relaciones con el precio de venta y las demás mencionadas.
- Interludio: ¿por qué se hacen transformaciones log?
- Apliquemos una transformación logarítmica al tamaño de la casa y al tamaño del terreno.
- Las *gráficas*
    #+name: figura 3
  - histograma lado a lado las relaciones mencionadas anteriormente
    #+name: figura 4
  - scatter plot lado a lados de las mismas relaciones (sin log vs log)
- 2.5% de las casas tienen un terreno de 436 ft^{2}.
- Las *gráficas*
    #+name: figura 5
  - bar plot del número de cuartos
  :depois:
  - ¿Cuál es la diferencia de bar plot e histograma?
  :END:
- Transormemos el número de cuartos en una característica cualitativa siendo los números del 1 al 7 iguales a una característica cuantitativa y de 8 en adelante siendo una característica cualitativa.
- Las *gráficas*
    #+name: figura 6
  - bar plot del número de cuartos (transformados a características cualitativas)

** Delving Deeper into Relationships
- Las *gráficas*
    #+name: figura 7
  - box plot del precio de las casas desmenuzado por el número de cuartos (cualitativo).
- Hacemos una nueva característica: precio por pie cuadrado y su transformación logarítmica.
- Las *gráficas*
    #+name: figura 8
  - scatter plot izq. y der.
    - izq.: precio vs. tamaño de la construcción
    - der.: precio por pie cuadrado (transformado logarítmicamente) vs. tamaño de la construcción
    - en cada una hay una curva ~lowess~ superpuesta que muestra promedios locales
** Fixing Location
- De las ciudades enlistadas se hace un desmenuce de su precio y se hace una gráfica.
- Las *gráficas*
    #+name: figura 9
    - box plot de la distribución del precio de las casas agrupados por las ciudades enlistadas
    #+name: figura 10
    - scatter plot (faceted) para cada ciudad enlistada (4 de ellas) x=bsqft, y=log_ppsf, trendline="ols"

** EDA Discoveries
- Sale price and building size are highly skewed to the right with one mode.
- Price per square foot decreases nonlinearly with building size, with samller houses costing more per square foot than larger houses and price per square foot being roughly constant for larger houses.
- More desirable locations add a bump in sale price that is roughly the same amount for houses of different sizes.
** DONE Gráficas [100%]
*** DONE {Figure,Axes} Títulos [10/10]
- [X] Gráfica 1
- [X] Gráfica 2
- [X] Gráfica 3
- [X] Gráfica 4
- [X] Gráfica 5
- [X] Gráfica 6
- [X] Gráfica 7
- [X] Gráfica 8
- [X] Gráfica 9
- [X] Gráfica 10
*** DONE {X,Y} Ticks [10/10]
- [X] Gráfica 1
- [X] Gráfica 2
- [X] Gráfica 3
- [X] Gráfica 4
- [X] Gráfica 5
- [X] Gráfica 6
- [X] Gráfica 7
- [X] Gráfica 8
- [X] Gráfica 9
- [X] Gráfica 10
*** DONE {X,Y} Labels [10/10]
- [X] Gráfica 1
- [X] Gráfica 2
- [X] Gráfica 3
- [X] Gráfica 4
- [X] Gráfica 5
- [X] Gráfica 6
- [X] Gráfica 7
- [X] Gráfica 8
- [X] Gráfica 9
- [X] Gráfica 10
* rcParams

* Footnotes
[fn:2] Explicar qué es la granularidad.

[fn:1] Explicar qué es un marco de acceso.
